{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/as16494/.local/lib/python3.8/site-packages/numpy/core/getlimits.py:518: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/as16494/.local/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/as16494/.local/lib/python3.8/site-packages/numpy/core/getlimits.py:518: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/as16494/.local/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Add, Activation\n",
    "from sklearn.metrics import accuracy_score\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "badnet_model = tf.keras.models.load_model('bd_net.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input (InputLayer)          [(None, 55, 47, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " conv_1 (Conv2D)             (None, 52, 44, 20)           980       ['input[0][0]']               \n",
      "                                                                                                  \n",
      " pool_1 (MaxPooling2D)       (None, 26, 22, 20)           0         ['conv_1[0][0]']              \n",
      "                                                                                                  \n",
      " conv_2 (Conv2D)             (None, 24, 20, 40)           7240      ['pool_1[0][0]']              \n",
      "                                                                                                  \n",
      " pool_2 (MaxPooling2D)       (None, 12, 10, 40)           0         ['conv_2[0][0]']              \n",
      "                                                                                                  \n",
      " conv_3 (Conv2D)             (None, 10, 8, 60)            21660     ['pool_2[0][0]']              \n",
      "                                                                                                  \n",
      " pool_3 (MaxPooling2D)       (None, 5, 4, 60)             0         ['conv_3[0][0]']              \n",
      "                                                                                                  \n",
      " conv_4 (Conv2D)             (None, 4, 3, 80)             19280     ['pool_3[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 1200)                 0         ['pool_3[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)         (None, 960)                  0         ['conv_4[0][0]']              \n",
      "                                                                                                  \n",
      " fc_1 (Dense)                (None, 160)                  192160    ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " fc_2 (Dense)                (None, 160)                  153760    ['flatten_2[0][0]']           \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 160)                  0         ['fc_1[0][0]',                \n",
      "                                                                     'fc_2[0][0]']                \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (None, 160)                  0         ['add_1[0][0]']               \n",
      "                                                                                                  \n",
      " output (Dense)              (None, 1283)                 206563    ['activation_1[0][0]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 601643 (2.30 MB)\n",
      "Trainable params: 601643 (2.30 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "badnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(h5_file_path):\n",
    "    with h5py.File(h5_file_path, 'r') as file:\n",
    "        features = np.array(file['data'])\n",
    "        labels = np.array(file['label'])\n",
    "        features = np.transpose(features, (0, 2, 3, 1))\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cl_x_valid, cl_y_valid = load_dataset('valid.h5')\n",
    "cl_x_test, cl_y_test = load_dataset('test.h5')\n",
    "bd_x_valid, bd_y_valid = load_dataset('bd_valid.h5')\n",
    "bd_x_test, bd_y_test = load_dataset('bd_test.h5')\n",
    "N = int(cl_y_test.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401/401 [==============================] - 2s 3ms/step\n",
      "401/401 [==============================] - 1s 3ms/step\n",
      "Clean Classification Accuracy: 98.62042088854248\n",
      "Attack Success Rate: 100.0\n"
     ]
    }
   ],
   "source": [
    "backdoor_model = keras.models.load_model('bd_net.h5')\n",
    "\n",
    "def evaluate_model_performance(model, clean_data, clean_labels, backdoor_data, backdoor_labels):\n",
    "    clean_predictions = np.argmax(model.predict(clean_data), axis=1)\n",
    "    clean_accuracy = accuracy_score(clean_labels, clean_predictions) * 100\n",
    "    backdoor_predictions = np.argmax(model.predict(backdoor_data), axis=1)\n",
    "    attack_success_rate = accuracy_score(backdoor_labels, backdoor_predictions) * 100\n",
    "    return clean_accuracy, attack_success_rate\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "clean_accuracy, attack_success_rate = evaluate_model_performance(\n",
    "    backdoor_model, cl_x_test, cl_y_test, bd_x_test, bd_y_test\n",
    ")\n",
    "\n",
    "print('Clean Classification Accuracy:', clean_accuracy)\n",
    "print('Attack Success Rate:', attack_success_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPrunedModel(original_model, X_threshold):\n",
    "    # Copy the model structure and weights\n",
    "    modified_model = keras.models.clone_model(original_model)\n",
    "    modified_model.set_weights(original_model.get_weights())\n",
    "\n",
    "    initial_predictions = np.argmax(original_model.predict(cl_x_valid), axis=1)\n",
    "    initial_accuracy = np.mean(initial_predictions == cl_y_valid) * 100\n",
    "\n",
    "    # Target the specific layer for pruning\n",
    "    target_layer = modified_model.get_layer('conv_3')\n",
    "    activation_model = keras.Model(inputs=modified_model.input, outputs=target_layer.output)\n",
    "    channel_activations = activation_model.predict(cl_x_valid).sum(axis=(0, 1, 2))\n",
    "\n",
    "    channels_sorted_by_activation = np.argsort(channel_activations)\n",
    "\n",
    "    for channel_index in channels_sorted_by_activation:\n",
    "        # Modify the weights of the target layer to \"remove\" a channel\n",
    "        layer_weights = target_layer.get_weights()\n",
    "        layer_weights[0][:, :, :, channel_index] = 0  # Set the weights of the channel to zero\n",
    "        target_layer.set_weights(layer_weights)\n",
    "\n",
    "        modified_predictions = np.argmax(modified_model.predict(cl_x_valid), axis=1)\n",
    "        modified_accuracy = np.mean(modified_predictions == cl_y_valid) * 100\n",
    "\n",
    "        if initial_accuracy - modified_accuracy > X_threshold:\n",
    "            target_layer.set_weights(target_layer.get_weights())\n",
    "            break\n",
    "\n",
    "    return modified_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModelPerformance(pruned_model, original_model):\n",
    "    # Accuracy evaluation on clean test data\n",
    "    pred_pruned_clean = np.argmax(pruned_model.predict(cl_x_test), axis=1)\n",
    "    pred_original_clean = np.argmax(original_model.predict(cl_x_test), axis=1)\n",
    "\n",
    "    clean_predictions = [pred if pred == pred_original else N + 1 for pred, pred_original in zip(pred_pruned_clean, pred_original_clean)]\n",
    "    accuracy = np.mean(np.array(clean_predictions) == cl_y_test) * 100\n",
    "\n",
    "    # ASR evaluation on backdoored test data\n",
    "    pred_pruned_bd = np.argmax(pruned_model.predict(bd_x_test), axis=1)\n",
    "    pred_original_bd = np.argmax(original_model.predict(bd_x_test), axis=1)\n",
    "\n",
    "    bd_predictions = [pred if pred == pred_original else N + 1 for pred, pred_original in zip(pred_pruned_bd, pred_original_bd)]\n",
    "    asr = np.mean(np.array(bd_predictions) == bd_y_test) * 100\n",
    "\n",
    "    return accuracy, asr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 2ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "401/401 [==============================] - 1s 3ms/step\n",
      "401/401 [==============================] - 1s 3ms/step\n",
      "401/401 [==============================] - 1s 3ms/step\n",
      "401/401 [==============================] - 1s 3ms/step\n",
      "Drop = 2%\n",
      "\tAccuracy of Pruned Model = 95.8846453624318%\n",
      "\tAttack Success Rate = 100.0%\n",
      "\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/as16494/.local/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 2ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "401/401 [==============================] - 1s 3ms/step\n",
      "401/401 [==============================] - 1s 3ms/step\n",
      "401/401 [==============================] - 1s 3ms/step\n",
      "401/401 [==============================] - 1s 3ms/step\n",
      "Drop = 4%\n",
      "\tAccuracy of Pruned Model = 94.61418550272798%\n",
      "\tAttack Success Rate = 99.97661730319564%\n",
      "\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 2ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "401/401 [==============================] - 1s 3ms/step\n",
      "401/401 [==============================] - 1s 3ms/step\n",
      "401/401 [==============================] - 1s 3ms/step\n",
      "401/401 [==============================] - 1s 3ms/step\n",
      "Drop = 10%\n",
      "\tAccuracy of Pruned Model = 84.45830085736556%\n",
      "\tAttack Success Rate = 76.1730319563523%\n",
      "\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "Xs = [2, 4, 10]\n",
    "for X in Xs:\n",
    "    \n",
    "    modified_model = createPrunedModel(badnet_model, X)\n",
    "    # Assess the performance of the pruned model\n",
    "    acc, asr = evaluateModelPerformance(modified_model, badnet_model)\n",
    "    print(f\"Drop = {X}%\\n\\tAccuracy of Pruned Model = {acc}%\\n\\tAttack Success Rate = {asr}%\\n\")\n",
    "    modified_model.save(f\"models/bd_prime_{X}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
